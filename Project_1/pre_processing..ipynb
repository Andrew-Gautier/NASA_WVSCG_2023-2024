{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Juliet_DB_loader import TestCase, Folder, SubFolder, sessionmaker, engine\n",
    "from sqlalchemy import func\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import re\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code can be used to verify a specific test cases's content and line number before any modifications are made\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = session.query(TestCase).filter_by(id=1000).first()\n",
    "line_content = dict()\n",
    "lines = test_cases.file_content.split('\\n')\n",
    "multiline_comment = False\n",
    "for line_num, line in enumerate(lines, start=1):\n",
    "    line_content[line_num] = line\n",
    "\n",
    "# Print the dictionary vertically\n",
    "for line_num, line in line_content.items():\n",
    "    print(f\"{line_num}: {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some checks I want to run is to see if my idea of holding the sting then updating the vulnerability line number will work. I think that I need to check that no comments exist on the line of the vulnerability location. I'd also like to generally print out a bunch of the vulnerability line locations, I will probably need to do this in conjunction with the linedict above to get the lines numbered. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vulnerable line: 43\n",
      "Total lines in file: 133\n",
      "43:         strcpy(data, source);\n"
     ]
    }
   ],
   "source": [
    "test_case = session.query(TestCase).filter_by(id=10000).first()\n",
    "line_content = dict()\n",
    "lines = test_case.file_content.split('\\n')\n",
    "vulnerable_line = int(test_case.vulnerability_location)\n",
    "\n",
    "print(f\"Vulnerable line: {vulnerable_line}\")\n",
    "print(f\"Total lines in file: {len(lines)}\")\n",
    "\n",
    "for line_num, line in enumerate(lines, start=1):\n",
    "    line_content[line_num] = line    \n",
    "\n",
    "# Check if vulnerable_line is a valid key in line_content\n",
    "if vulnerable_line in line_content:\n",
    "    print(f\"{vulnerable_line}: {line_content[vulnerable_line]}\")\n",
    "else:\n",
    "    print(f\"Vulnerable line {vulnerable_line} is not in the file content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lex and Yacc Parser Method\n",
    "I'm going to mess around with a simple parser to see if it can properly strip whitespace rather than the faulty regular expressions I was using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No t_error rule is defined\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'__file__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mp_error\u001b[39m(p):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSyntax error in input!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 28\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43myacc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myacc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwrite_tables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstrip_comments_and_preserve_line_numbers\u001b[39m(code):\n\u001b[0;32m     31\u001b[0m     parsed_code \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse(code)\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\Desktop\\nasa_project\\Project_1\\.venv\\Lib\\site-packages\\ply\\yacc.py:3256\u001b[0m, in \u001b[0;36myacc\u001b[1;34m(method, debug, module, tabmodule, start, check_recursion, optimize, write_tables, debugfile, outputdir, debuglog, errorlog, picklefile)\u001b[0m\n\u001b[0;32m   3254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tabmodule:\n\u001b[1;32m-> 3256\u001b[0m         srcfile \u001b[38;5;241m=\u001b[39m \u001b[43mpdict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__file__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3257\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3258\u001b[0m         parts \u001b[38;5;241m=\u001b[39m tabmodule\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '__file__'"
     ]
    }
   ],
   "source": [
    "import ply.lex as lex\n",
    "import ply.yacc as yacc\n",
    "\n",
    "\n",
    "# Define tokens\n",
    "tokens = ['COMMENT', 'CODE']\n",
    "\n",
    "# Define rules\n",
    "t_COMMENT = r'(/\\*([^*]|[\\r\\n]|(\\*+([^*/]|[\\r\\n])))*\\*+/)|(//.*)'\n",
    "t_CODE = r'[^\\n]+'\n",
    "\n",
    "# Define lexer\n",
    "lexer = lex.lex()\n",
    "\n",
    "# Define parser\n",
    "def p_code(p):\n",
    "    '''code : code COMMENT\n",
    "            | code CODE\n",
    "            | COMMENT\n",
    "            | CODE'''\n",
    "    if len(p) == 2:\n",
    "        p[0] = p[1]\n",
    "    elif len(p) == 3:\n",
    "        p[0] = p[1] + p[2]\n",
    "def p_error(p):\n",
    "    print(\"Syntax error in input!\")\n",
    "    \n",
    "parser = yacc.yacc(write_tables=False)\n",
    "\n",
    "def strip_comments_and_preserve_line_numbers(code):\n",
    "    parsed_code = parser.parse(code)\n",
    "    return parsed_code\n",
    "c_code = session.query(TestCase).filter_by(id=60000).first()\n",
    "\n",
    "\n",
    "stripped_code = strip_comments_and_preserve_line_numbers(c_code)\n",
    "print(stripped_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
